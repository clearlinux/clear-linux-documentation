

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
<script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga");ga("create", "UA-61272224-1", {"cookieDomain":"auto","allowLinker":true});ga("require", "linker");ga("linker:autoLink", [/(community\.|www\.|^)clearlinux\.org/gi], true);ga("set", "anonymizeIp", true);ga("send", "pageview");</script>


  <title>Deep Learning Reference Stack &mdash; Documentation for Clear Linux* project</title>
  



  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  
    <link rel="canonical" href="docs.01.org/clearlinux/tutorials/dlrs.html"/>
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="author" title="关于这些文档" href="../about.html" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="Docker*" href="docker.html" />
    <link rel="prev" title="Apache* Spark*" href="apache-spark.html" />

<link rel="stylesheet" href="../_static/tcs_theme.css" type="text/css" />


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #007ab2" >
          

          
            <a href="../index.html" class="icon icon-home"> Clear Linux* Project Docs
          

          
            
            <img src="../_static/clearlinux.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" id="clear-docs-search" placeholder="Search documentation" results="0"/>
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Clear Linux</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Language Versions</dt>
        
          <dd><a href="/clearlinux/latest/tutorials/dlrs.html">English</a></dd>
        
          <dd><a href="/clearlinux/latest/zh_CN/tutorials/dlrs.html">简体中文 (Simplified Chinese)</a></dd>
        
      </dl>
      <dl>
        <dt>Document Versions</dt>
        
          <dd><a href="/clearlinux/latest/tutorials/dlrs.html">latest</a></dd>
        
          <dd><a href="/clearlinux/latest/tutorials/dlrs.html">Future versions</a></dd>
        
      </dl>
      <dl>
        <dt>clearlinux.org links</dt>
          <dd>
            <a href="https://www.clearlinux.org/">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/clearlinux/clear-linux-documentation">GitHub</a>
          </dd>
      </dl>
    </div>
  </div>
  
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../get-started/index.html">开始使用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../get-started/index.html#pre-install">安装前</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../get-started/compatibility-check.html">检查处理器和 EFI 固件的兼容性</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/compatibility-check.html#check-compatibility">检查兼容性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/bootable-usb.html">创建可引导 U 盘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bootable-usb.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bootable-usb.html#create-a-bootable-usb-drive-on-linux">在 Linux* 上创建可引导 U 盘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bootable-usb.html#create-a-bootable-usb-drive-on-macos">在 macOS* 上创建可引导 U 盘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bootable-usb.html#create-a-bootable-usb-drive-on-windows">在 Windows* 上创建可引导 U 盘</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../get-started/index.html#install">安装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html">从实时桌面安装 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#system-requirements">系统要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#preliminary-steps">初始步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#install-from-live-image">从实时映像安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#minimum-installation-requirements">最低安装要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#cl-desktop-installer">Clear Linux OS 桌面安装程序</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#navigation">导航</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#required-options">必填选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#advanced-options">高级选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#finish-installation">完成安装</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/bare-metal-install-server.html">使用实时服务器将 Clear Linux* OS 安装在裸机上</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#system-requirements">系统要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#download-the-latest-cl-live-server-image">下载最新的 Clear Linux OS 实时服务器映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#install-cl-on-your-target-system">在目标系统上安装 Clear Linux OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#launch-the-cl-installer">启动 Clear Linux OS 安装程序</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#minimum-installation-requirements">最低安装要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#main-menu">主菜单</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#navigation">导航</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#required-options">必填选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#recommended-options">推荐选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#advanced-options">高级选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#finish-installation">完成安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/bare-metal-install-server.html#troubleshooting">故障检修</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/install-configfile.html">利用 clr-installer 和配置文件安装</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/install-configfile.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/install-configfile.html#process">流程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/install-configfile.html#references">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../get-started/index.html#install-in-a-virtual-machine">在虚拟机上安装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/hyper-v.html">Microsoft Hyper-V* 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/hyper-v.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/hyper-v.html#enable-hyper-v">启用 Hyper-V</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/hyper-v.html#create-a-virtual-network">创建虚拟网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/hyper-v.html#create-a-virtual-machine">创建虚拟机</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/kvm.html">KVM 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/kvm.html#install-qemu-kvm">安装 QEMU-KVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/kvm.html#download-and-launch-the-virtual-machine">下载并开启虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/kvm.html#ssh-access-into-the-virtual-machine">通过 SSH 访问虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/kvm.html#optional-add-the-gnome-display-manager-gdm">可选：添加 GNOME Display Manager (GDM)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html">VirtualBox* 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html#download-and-extract-the-cl-installer-iso">下载并解压缩 Clear Linux OS 安装程序 ISO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html#create-a-new-vb-virtual-machine">创建新的 VirtualBox 虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html#install-cl-on-the-vb-vm">在 VirtualBox 虚拟机上安装 Clear Linux OS。</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/virtualbox-cl-installer.html#troubleshooting">故障检修</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html">VMware* Workstation Player 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#install-the-vmware-workstation-player-hypervisor">安装 VMware Workstation Player 虚拟机管理程序</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#download-the-latest-cl-installer">下载最新的 Clear Linux OS 安装程序</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#create-and-configure-a-new-vm">创建并配置新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#enable-uefi-boot-support">启用 UEFI 引导支持</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#install-cl-into-the-new-vm">将 Clear Linux OS 安装至新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#detach-the-cl-installer-iso-from-the-vm">从虚拟机断开 Clear Linux OS 安装程序 ISO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#install-open-vm-tools">安装 open-vm-tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html">VMware* Workstation Player （预配置映像）上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#install-the-vmware-workstation-player-hypervisor">安装 VMware Workstation Player 虚拟机管理程序</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#download-the-latest-cl-vmware-image">下载最新的 Clear Linux OS VMware 映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#decompress-and-verify-the-image">解压缩并验证映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#create-and-configure-a-new-vm">创建并配置新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#attach-the-pre-configured-cl-vmware-image">挂载预配置的 Clear Linux OS Vmware 映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#enable-uefi-boot-support">启用 UEFI 引导支持</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#power-on-the-vm">开启虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmw-player-preconf.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html">VMware* ESXi 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#download-the-latest-cl-installer-iso">下载最新的 Clear Linux OS 安装程序 ISO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#upload-the-cl-installer-iso-to-the-vmware-server">将 Clear Linux OS 安装程序 ISO 上传至 VMware 服务器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#create-and-configure-a-new-vm">创建并配置新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#install-cl-into-the-new-vm">将 Clear Linux OS 安装至新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#reconfigure-the-vm-s-settings-to-boot-the-newly-installed-cl">重新配置虚拟机设置，以引导新安装的 Clear Linux OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#power-on-the-vm-and-boot-cl">开启虚拟机，引导 Clear Linux OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-install-cl.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html">VMware* ESXi（预配置映像）上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#download-the-latest-cl-vmware-image">下载最新的 Clear Linux OS VMware 映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#upload-the-cl-image-to-the-vmware-server">将 Clear Linux OS 映像上传至 VMware 服务器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#convert-the-cl-image-to-an-esxi-supported-format">将 Clear Linux OS 映像转换为 ESXi 支持的格式。</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#create-and-configure-a-new-vm">创建并配置新虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#power-on-the-vm-and-boot-cl">开启虚拟机，引导 Clear Linux OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/virtual-machine-install/vmware-esxi-preconfigured-cl-image.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html">增加映像的虚拟磁盘大小</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html#determine-the-partition-order-and-sizes-of-the-prebuilt-image">确定预构建映像的分区顺序和大小。</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html#id2">增加虚拟盘大小</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../get-started/index.html#deploy-to-the-cloud">部署到云</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../get-started/cloud-install/aws-web.html">Amazon Web Services* 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/aws-web.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/aws-web.html#locate-select-and-launch-the-cl-basic-ami">找到、选择并启动 Clear Linux OS 基本 AMI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/aws-web.html#connect-to-your-clear-linux-os-basic-instance">连接到 Clear Linux 操作系统基本实例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/aws-web.html#update-the-cl-instance">更新 Clear Linux OS 实例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/aws-web.html#stop-the-cl-instance">停止 Clear Linux OS 实例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/cloud-install/azure.html">Microsoft* Azure* 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#install-ms-azure-cli-2-0-on-cl">在 Clear Linux OS 中安装 Microsoft Azure CLI 2.0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#log-into-your-microsoft-azure-account">登录到您的 Microsoft Azure 帐户</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#create-a-ms-azure-resource-group">创建 Microsoft Azure 资源组</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#create-and-log-into-the-cl-virtual-machine">创建 Clear Linux OS 虚拟机并登录到该虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#stop-and-deallocate-the-cl-vm-and-resources">停止并取消分配 Clear Linux OS 虚拟机和资源</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/azure.html#next-steps">后续步骤</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/cloud-install/gce.html">Google Cloud Platform* 上的 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/gce.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/gce.html#setup-cl-vm-on-gcp">在 GCP 上安装 Clear Linux OS 虚拟机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/gce.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html">Clear Linux* OS on QingCloud* (如何在青云 QingCloud 上创建 Clear Linux OS 虚拟主机)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#id2">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#qingcloud-cl">在 QingCloud 控制台中选择并启动 Clear Linux OS 虚拟主机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#ip">申请公网IP并添加到虚拟主机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#cl">连接到 Clear Linux OS 虚拟主机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#id3">删除 Clear Linux OS 虚拟主机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../get-started/cloud-install/qingcloud.html#id4">删除申请的公网IP</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">关于</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../about.html#release-cadence">发行节奏</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#updates">更新</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#ease-of-use">易用性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#custom-derivatives">自定义衍生工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../about.html#create">创建</a></li>
<li class="toctree-l3"><a class="reference internal" href="../about.html#deploy">部署</a></li>
<li class="toctree-l3"><a class="reference internal" href="../about.html#administrate">管理</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../guides/index.html">指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../guides/index.html#clear-linux">Clear Linux</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/autoproxy.html">Autoproxy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autoproxy.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autoproxy.html#how-it-works">工作原理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/autospec.html">autospec</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#how-it-works">工作原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#test-packaged-software">测试封装后的软件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#references">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/autospec.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/bundles.html">bundle 文件</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/bundles.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/compatible-kernels.html">内核</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/compatible-kernels.html#bare-metal-only">仅限裸机</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/compatible-kernels.html#also-compatible-with-vms">也与虚拟机兼容</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/compatible-kernels.html#vm-only">仅限虚拟机</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/debug.html">调试系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/debug.html#background">后台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/debug.html#usage">用途</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/debug.html#implementation">实施</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/ister.html">ister.py image builder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/ister.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/ister.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/ister.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/mixer.html">mixer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/mixer.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/mixer.html#how-it-works">工作原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/mixer.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/mixer.html#references">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/mixer.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/security.html">操作系统安全性</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/security.html#security-in-updates">更新方面的安全举措</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/security.html#security-in-software">软件方面的安全举措</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/security.html#security-in-system-design">系统设计方面的安全举措</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/stateless.html">无状态</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/stateless.html#file-level-separation">文件级隔离</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/stateless.html#software-configuration">软件配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/stateless.html#system-reset">系统重置</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/stateless.html#additional-information">附加说明</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/swupd.html">swupd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/swupd.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/swupd.html#how-it-works">工作原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/swupd.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/swupd.html#quick-reference">快速参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/swupd.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/clear/telemetrics.html">遥测</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/telemetrics.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/telemetrics.html#how-to-use">使用方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/telemetrics.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/clear/telemetrics.html#reference">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../guides/index.html#maintenance">维护</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html">设计 Clear Linux* OS 生命周期</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html#content-workflow">内容工作流程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html#release-workflow">版本工作流程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/architect-lifecycle.html#implementation">实施</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/assign-static-ip.html">分配静态 IP 地址</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/assign-static-ip.html#identify-which-program-is-managing-the-interface">确定哪个程序正在管理接口</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/assign-static-ip.html#using-networkmanager">使用 NetworkManager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/assign-static-ip.html#using-systemd-networkd">使用 systemd-networkd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/bulk-provision.html">批量供应</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/bulk-provision.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/bulk-provision.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/bulk-provision.html#configuration">配置</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/cpu-performance.html">CPU 功率和性能</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/cpu-performance.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/cpu-performance.html#cpu-power-saving-mechanisms">CPU 节能机制</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/cpu-performance.html#linux-cpu-clock-frequency-scaling">Linux CPU 时钟频率缩放</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/cpu-performance.html#thermal-management">散热管理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/deploy-at-scale.html">大规模部署</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/deploy-at-scale.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/deploy-at-scale.html#pick-a-usage-and-update-strategy">选择使用和更新策略</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/deploy-at-scale.html#pick-an-image-distribution-strategy">选择映像分发策略</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/deploy-at-scale.html#considerations-with-stateless-systems">有关无状态系统的注意事项</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/developer-workstation.html">开发人员工作站</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/developer-workstation.html#workstation-setup">工作站设置</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/developer-workstation.html#swupd-search">swupd 搜索</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/developer-workstation.html#core-concepts">核心概念</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/download-verify-decompress.html">下载、验证并解压缩 Clear Linux* OS 映像，</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/download-verify-decompress.html#linux-os-steps">Linux 操作系统步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/download-verify-decompress.html#macos-steps">macOS* 步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/download-verify-decompress.html#windows-os-steps">Windows* 操作系统步骤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/download-verify-decompress.html#image-types">映像类型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/enable-user-space.html">创建并启用新的用户空间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/enable-user-space.html#create-a-new-user">创建新用户</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/enable-user-space.html#add-the-new-user-to-the-wheel-group">将新用户添加到 wheel 组</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/enable-user-space.html#install-and-update-the-os-software-to-its-current-version">安装操作系统软件并将其更新到最新版本</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/enable-user-space.html#add-a-bundle">添加捆绑包</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/enable-user-space.html#next-steps">后续步骤</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html">修复损坏的安装</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html#boot-a-live-desktop-image-to-fix-target-system">引导实时桌面映像来修复目标系统</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html#install-from-live-image">从实时映像安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/fix-broken-install.html#mount-root-partition-verify-and-fix">挂载根分区，然后验证并修复</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/hostname.html">修改主机名</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/hostname.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/hostname.html#set-your-hostname">设置主机名</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/hostname.html#view-your-hostname">查看主机名</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html">增加映像的虚拟磁盘大小</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html#determine-the-partition-order-and-sizes-of-the-prebuilt-image">确定预构建映像的分区顺序和大小。</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/increase-virtual-disk-size.html#id2">增加虚拟盘大小</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/query-upstream.html">从上游存储库查询软件包信息</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/query-upstream.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/query-upstream.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/query-upstream.html#configure-dnf">配置 DNF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/query-upstream.html#dnf-command-usage-examples">DNF 命令用法示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/resource-limits.html">资源限制</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/resource-limits.html#system-wide-limits">系统范围限制</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/resource-limits.html#per-user-limits">每用户限制</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/resource-limits.html#service-limits">服务限制</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/restart.html">操作系统更新后重启系统服务</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#how-it-works">工作原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#basic-options">基本选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#monitor-options">监控选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#example">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#telemetry">遥测技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/restart.html#conclusion">总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/time.html">设置时间</a></li>
<li class="toctree-l3"><a class="reference internal" href="../guides/maintenance/validate-signatures.html">验证签名</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/validate-signatures.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/validate-signatures.html#image-content-validation">映像内容验证</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/maintenance/validate-signatures.html#update-content-validation">更新内容验证</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../guides/index.html#network">网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/custom-clear-container.html">根据 Docker 容器映像构建一个自定义 Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/custom-clear-container.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/custom-clear-container.html#build-the-base-container-image">构建基础容器映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/custom-clear-container.html#manage-bundles-in-a-container">管理容器中的捆绑包</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/dpdk.html">使用 DPDK 在平台之间发送数据包</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#install-dpdk-and-build-l3fwd-example-platform-b">安装 dpdk 并构建 l3fwd 示例（平台 B）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#build-pktgen-platform-a">构建 pktgen（平台 A）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#bind-nics-to-dpdk-kernel-drivers-platforms-a-and-b">将网卡绑定到 DPDK 内核驱动程序（平台 A 和平台 B）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#set-hugepages-platforms-a-and-b">设置大页（平台 A 和 B）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#set-up-the-physical-environment-platforms-a-and-b">设置物理环境（平台 A 和 B）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#run-l3fwd-application-platform-b">运行 l3fwd 应用程序（平台 B）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#run-pktgen-application-platform-a">运行 pktgen 应用程序（平台 A）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/dpdk.html#appendix-a-use-pass-through-for-virtual-machines">附录 A：为虚拟机使用直通</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/ipxe-install.html">使用 iPXE 通过网络安装</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/ipxe-install.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/ipxe-install.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/ipxe-install.html#configuration">配置</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/network-bonding.html">使用网络捆绑聚合多个接口</a></li>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/openssh-server.html">启用并配置 SSH 服务</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#prerequisites">必备条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#change-default-port">更改默认端口</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#enable-sftp">启用 SFTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#enable-root-login">启用 root 登录</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/openssh-server.html#enable-x11-forwarding">启用 X11 转发</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/network/vnc.html">使用 VNC 通过远程桌面连接到主机</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#install-the-vnc-server-and-misc-components-on-your-host">在主机上安装 VNC 服务器和其他组件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#configure-a-vnc-server-start-method-on-your-host">在主机上配置 VNC-server-start 方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#install-a-vnc-viewer-app-and-an-ssh-client-on-your-client-system">在客户端系统上安装一个 VNC 查看器应用程序和一个 SSH 客户端</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#establish-a-vnc-connection-to-your-host">与主机建立 VNC 连接</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#terminate-a-vnc-connection-to-your-host">终止与主机的 VNC 连接</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/network/vnc.html#encrypt-vnc-traffic-through-an-ssh-tunnel">通过 SSH 隧道加密 VNC 流量</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../guides/index.html#kernel">内核</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/kernel/kernel-development.html">内核开发</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#request-changes-be-included-with-the-cl-kernel">Clear Linux OS 内核中包含了请求变更</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#set-up-kernel-development-environment">设置内核开发环境</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#customize-the-linux-kernel-source">自定义 Linux 内核源代码</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#build-and-install-the-kernel">构建并安装内核</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-development.html#related-topics">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/kernel/kernel-modules.html">手动添加内核模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#kernel-module-availability">内核模块可用性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#build-install-and-load-an-out-of-tree-module">构建、安装和加载树外模块</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules.html#related-topic">相关主题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html">使用 DKMS 添加内核模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#description">描述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#kernel-module-availability">内核模块可用性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#install-dkms">安装 DKMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#build-install-and-load-an-out-of-tree-module">构建、安装和加载树外模块</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#examples">示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/kernel/kernel-modules-dkms.html#related-topics">相关主题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../guides/index.html#stacks">堆栈</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/stacks/dars.html">数据分析参考堆栈</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dars.html#the-data-analytics-reference-stack-release">数据分析参考堆栈版本</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dars.html#using-the-docker-images">使用 Docker 映像</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dars.html#building-dars-images">构建 DARS 映像</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/stacks/greengrass.html">启用 AWS Greengrass* 和 OpenVINO™ 工具包</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#supported-platforms">支持的平台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#install-the-os-on-the-edge-device">在边缘设备上安装操作系统</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#configure-aws-greengrass-group">配置 AWS Greengrass 组</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#create-and-package-lambda-function">创建并打包 Lambda 函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#configure-lambda-function">配置 Lambda 函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#deploy-lambda-function">部署 Lambda 函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/greengrass.html#references">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html">深度学习参考堆栈</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#overview">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow 单节点和多节点基准测试</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch 单节点和多节点基准测试</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#kubeflow-multi-node-benchmarks">Kubeflow 多节点基准测试</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#use-jupyter-notebook">使用 Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#uninstallation">卸载</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guides/stacks/dlrs/dlrs.html#related-topics">相关主题</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="apache-hadoop.html">Apache* Hadoop*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#install-apache-hadoop">Install Apache Hadoop</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#configure-apache-hadoop">Configure Apache Hadoop</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#configure-your-ssh-key">Configure your SSH key</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#run-the-hadoop-daemons">Run the Hadoop daemons</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-hadoop.html#run-the-mapreduce-wordcount-example">Run the MapReduce wordcount example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-spark.html">Apache* Spark*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-spark.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-spark.html#install-apache-spark">Install Apache Spark</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-spark.html#configure-apache-spark">Configure Apache Spark</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-spark.html#start-the-master-server-and-a-worker-daemon">Start the master server and a worker daemon</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-spark.html#run-the-spark-wordcount-example">Run the Spark wordcount example</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Deep Learning Reference Stack</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="#version-compatibility">Version compatibility</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kubeflow-multi-node-benchmarks">Kubeflow multi-node benchmarks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#kubernetes-setup">Kubernetes setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kubernetes-networking">Kubernetes networking</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kubectl">Kubectl</a></li>
<li class="toctree-l4"><a class="reference internal" href="#images">Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ksonnet">ksonnet*</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kubeflow">Kubeflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-a-tfjob">Run a TFJob</a></li>
<li class="toctree-l4"><a class="reference internal" href="#results-of-running-this-section">Results of running this section</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#submitting-tfjobs">Submitting TFJobs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#customizing-a-tfjob">Customizing a TFJob</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#submitting-pytorch-jobs">Submitting PyTorch Jobs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#using-kubeflow-seldon-and-openvino-with-the-deep-learning-reference-stack">Using Kubeflow Seldon and OpenVINO* with the Deep Learning Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pre-requisites">Pre-requisites</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#using-the-intel-openvino-model-optimizer">Using the Intel® OpenVINO Model Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-the-openvino-inference-engine">Using the OpenVino Inference Engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="#uninstallation">Uninstallation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#related-topics">Related topics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="docker.html">Docker*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="docker.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#install-the-containers-basic-bundle">Install the containers-basic bundle</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#integration-with-kata-containers-optional">Integration with Kata Containers* (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#additional-docker-configuration">Additional Docker configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#pulling-and-running-an-image-from-docker-hub">Pulling and running an image from Docker Hub</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#creating-a-docker-swarm-cluster">Creating a Docker swarm cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="docker.html#related-topics">Related topics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="flatpak.html">Flatpak*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="flatpak.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="flatpak.html#install-a-flatpak-app-with-gnome-software">Install a Flatpak app with Gnome Software</a></li>
<li class="toctree-l3"><a class="reference internal" href="flatpak.html#install-a-flatpak-with-the-command-line">Install a Flatpak with the command line</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="fmv.html">Function multi-versioning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="fmv.html#install-and-configure-a-cl-host-on-bare-metal">Install and configure a Clear Linux OS host on bare metal</a></li>
<li class="toctree-l3"><a class="reference internal" href="fmv.html#detect-loop-vectorization-candidates">Detect loop vectorization candidates</a></li>
<li class="toctree-l3"><a class="reference internal" href="fmv.html#generate-the-fmv-patch">Generate the FMV patch</a></li>
<li class="toctree-l3"><a class="reference internal" href="fmv.html#fft-project-example-using-fftw">FFT project example using FFTW</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kata.html">Kata Containers*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kata.html#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="kata.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="kata.html#install-kata-containers">Install Kata Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="kata.html#run-kata-containers">Run Kata Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="kata.html#more-information-about-docker">More information about Docker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kata.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kubernetes.html">Kubernetes*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#install-kubernetes-and-cri-runtimes">Install Kubernetes and CRI runtimes</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#configure-kubernetes">Configure Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#configure-and-run-kubernetes">Configure and run Kubernetes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kubernetes.html#configure-and-run-cri-o-kata-runtime">Configure and run CRI-O + kata-runtime</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#install-pod-network-add-on">Install pod network add-on</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#use-your-cluster">Use your cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#related-topics">Related topics</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#cloud-native-setup-automation">Cloud native setup automation</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#package-configuration-customization-optional">Package configuration customization (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#proxy-configuration-optional">Proxy configuration (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kubernetes-bp.html">Kubernetes* Best Practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kubernetes-bp.html#use-swupd-to-update-clusters">Use swupd to update clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes-bp.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes-bp.html#update-the-control-plane">Update the control plane</a></li>
<li class="toctree-l3"><a class="reference internal" href="kubernetes-bp.html#update-worker-nodes">Update worker nodes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nvidia.html">NVIDIA* Drivers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#install-dkms">Install DKMS</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#download-and-install-the-nvidia-drivers">Download and install the NVIDIA drivers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nvidia.html#download-the-nvidia-drivers-for-linux">Download the NVIDIA drivers for Linux</a></li>
<li class="toctree-l4"><a class="reference internal" href="nvidia.html#disable-the-nouveau-driver">Disable the nouveau driver</a></li>
<li class="toctree-l4"><a class="reference internal" href="nvidia.html#configure-alternative-software-paths">Configure alternative software paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="nvidia.html#install-the-nvidia-drivers">Install the NVIDIA drivers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#updating-the-nvidia-drivers">Updating the NVIDIA drivers</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#uninstalling-the-nvidia-drivers">Uninstalling the NVIDIA drivers</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#debugging-installation-of-nvidia-drivers">Debugging installation of NVIDIA drivers</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia.html#additional-resources">Additional resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nvidia-cuda.html">NVIDIA* CUDA Toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#compatibility">Compatibility</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nvidia-cuda.html#check-compatibility-of-nvidia-components">Check compatibility of NVIDIA components</a></li>
<li class="toctree-l4"><a class="reference internal" href="nvidia-cuda.html#check-gcc-compatibility">Check GCC compatibility</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#downloading-and-installation">Downloading and Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nvidia-cuda.html#download-the-nvidia-cuda-toolkit">Download the NVIDIA CUDA Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="nvidia-cuda.html#install-the-nvidia-cuda-toolkit">Install the NVIDIA CUDA Toolkit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#using-the-nvidia-cuda-toolkit">Using the NVIDIA CUDA Toolkit</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#uninstalling">Uninstalling</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#debugging">Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="nvidia-cuda.html#additional-resources">Additional resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="parallels.html">Parallels* Desktop for Mac*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="parallels.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="parallels.html#download-iso-image">Download ISO image</a></li>
<li class="toctree-l3"><a class="reference internal" href="parallels.html#initialize-new-vm">Initialize new VM</a></li>
<li class="toctree-l3"><a class="reference internal" href="parallels.html#install-cl-on-vm">Install Clear Linux OS on VM</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="proxy.html">Proxy configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="proxy.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="proxy.html#shells-and-programs-in-a-desktop-session">Shells and programs in a desktop session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="proxy.html#terminal">Terminal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="proxy.html#wget">wget</a></li>
<li class="toctree-l3"><a class="reference internal" href="proxy.html#system-service-docker">System service (Docker)</a></li>
<li class="toctree-l3"><a class="reference internal" href="proxy.html#git-over-ssh">git over ssh</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="redis.html">Redis*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="redis.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html#install-the-redis-bundle">Install the redis bundle</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html#start-the-redis-server">Start the redis-server</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html#example-1-use-the-redis-cli-and-try-commands">Example 1: Use the redis-cli and try commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html#example-2-run-the-cl-redis-docker-image">Example 2: Run the Clear Linux OS redis docker image</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html#next-steps">Next Steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="smb.html">Samba* as a host</a><ul>
<li class="toctree-l3"><a class="reference internal" href="smb.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="smb.html#set-up-file-sharing">Set up file sharing</a></li>
<li class="toctree-l3"><a class="reference internal" href="smb.html#map-cl-drive-in-windows">Map Clear Linux OS drive in Windows</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="smb-desktop.html">Samba* as a client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="smb-desktop.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="smb-desktop.html#connect-to-windows-shared-location-with-nautilus">Connect to Windows shared location with Nautilus</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-machine-learning.html">TensorFlow* machine learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tensorflow-machine-learning.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow-machine-learning.html#set-up-a-jupyter-notebook">Set up a Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow-machine-learning.html#run-the-jupyter-machine-learning-example-code">Run the Jupyter machine learning example code</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow-machine-learning.html#related-topics">Related topics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="wordpress.html">WordPress*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="wordpress/web-server-install.html">Set up a LAMP web server on Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#install-apache">Install Apache</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#change-the-default-configuration-and-data-directory">Change the default configuration and data directory</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#install-php">Install PHP</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#install-mariadb">Install MariaDB</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#install-phpmyadmin">Install phpMyAdmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#use-phpmyadmin-to-manage-a-database">Use phpMyAdmin to manage a database</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/web-server-install.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="wordpress/wp-install.html">Set up WordPress* on a LAMP web server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="wordpress/wp-install.html#before-you-begin">Before you begin</a></li>
<li class="toctree-l4"><a class="reference internal" href="wordpress/wp-install.html#create-a-wordpress-server">Create a WordPress server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="yubikey-u2f.html">YubiKey* Support</a><ul>
<li class="toctree-l3"><a class="reference internal" href="yubikey-u2f.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="yubikey-u2f.html#enable-linux-udev-rules-for-yubikey">Enable Linux udev rules for YubiKey</a></li>
<li class="toctree-l3"><a class="reference internal" href="yubikey-u2f.html#enable-u2f-in-mozilla-firefox">Enable U2F in Mozilla Firefox</a></li>
<li class="toctree-l3"><a class="reference internal" href="yubikey-u2f.html#related-topics">Related topics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#archive">Archive</a><ul>
<li class="toctree-l3"><a class="reference internal" href="archive/kata_migration.html">Migrate Clear Containers to Kata Containers*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="archive/kata_migration.html#stop-clear-containers-instances">Stop Clear Containers instances</a></li>
<li class="toctree-l4"><a class="reference internal" href="archive/kata_migration.html#manually-migrate-customized-configuration-files">Manually migrate customized configuration files</a></li>
<li class="toctree-l4"><a class="reference internal" href="archive/kata_migration.html#enable-kata-containers-as-default">Enable Kata Containers as default</a></li>
<li class="toctree-l4"><a class="reference internal" href="archive/kata_migration.html#run-kata-containers">Run Kata Containers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reference/compatible-hardware.html">Compatible Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/bundles/bundles.html">可用的捆绑包</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/bundles/bundles.html#bundle-list">捆绑包列表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../reference/collaboration/collaboration.html">Documentation guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/collaboration/collaboration.html#contribution-guidelines">Contribution guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../reference/collaboration/writing-guide.html">Writing guide: Describes the style we use to keep our documents clear and concise.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../reference/collaboration/structure-formatting.html">Structure and formatting guide: Explains how we organize and format content, using reStructuredText and Sphinx.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../reference/collaboration/collaboration.html#how-to-contribute">How to contribute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/collaboration/collaboration.html#contribute-via-github">Contribute via GitHub</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/collaboration/collaboration.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../reference/system-requirements.html">建议的最低系统要求</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../reference/system-requirements.html#installer-requirements">安装程序要求</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/system-requirements.html#id1">系统要求</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reference/system-requirements.html#recommended-configurations">建议配置</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../reference/image-types.html">Clear Linux* OS image types</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ/index.html">FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../FAQ/index.html#general">General</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#why-did-you-make-another-distro">Why did you make another distro?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#can-other-distros-copy-cl-improvements">Can other distros copy Clear Linux OS improvements?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#how-often-do-you-update">How often do you update?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#is-telemetry-required">Is telemetry required?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#what-is-the-default-firewall">What is the default firewall?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#where-are-the-files-that-i-usually-see-under-etc-like-fstab">Where are the files that I usually see under /etc like fstab?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../FAQ/index.html#software-packages">Software packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#how-is-software-installed-and-updated">How is software installed and updated?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#does-cl-use-rpms-like-other-distros">Does Clear Linux OS use RPMs like other distros?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#can-i-install-a-software-package-from-another-os-on-cl">Can I install a software package from another OS on Clear Linux OS?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../FAQ/index.html#software-availability">Software availability</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#what-software-is-available-on-cl">What software is available on Clear Linux OS?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#is-google-chrome-available">Is Google* Chrome* available?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#is-microsoft-visual-studio-code-available">Is Microsoft* Visual Studio Code* available?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#is-ffmpeg-available">Is FFmpeg available?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#is-zfs-available">Is ZFS* available?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FAQ/index.html#can-you-add-a-driver-that-i-need">Can you add a driver that I need?</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Clear Linux* Project Docs</a>
        
      </nav>


      <div class="wy-nav-content">

<header id="header">
  <div class="padding-md--left-right">

    <div class="header__site_info">
           <div class="header__site_info_name">
           </div>
    </div>
    <nav class="header__menu">
        <ul class="header__menu_list">
              <li class="header__menu_list_item yellow  ">
                <a tabindex='1' href="https://clearlinux.org">Home</a>
              </li>
              <li class="header__menu_list_item green  ">
                <a tabindex='1' href="https://clearlinux.org/about">About</a>
              </li>
              <li class="header__menu_list_item purple  ">
                <a tabindex='1' href="https://clearlinux.org/developer">Developer</a>
              </li>
              <li class="header__menu_list_item blue  ">
                <a tabindex='1' href="https://clearlinux.org/software">Software</a>
              </li>
        </ul>
    </nav>

  </div>

</header>


        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Tutorials</a> &raquo;</li>
        
      <li>Deep Learning Reference Stack</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/clearlinux/clear-linux-documentation/blob/master/source/tutorials/dlrs.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="deep-learning-reference-stack">
<span id="dlrs"></span><h1>Deep Learning Reference Stack<a class="headerlink" href="#deep-learning-reference-stack" title="永久链接至标题">¶</a></h1>
<p>This guide gives examples for using the Deep Learning Reference stack to run real-world usecases, as well as benchmarking workloads for TensorFlow*,
PyTorch*, and Kubeflow* in Clear Linux* OS.</p>
<div class="contents local topic" id="id1">
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id4">Overview</a></li>
<li><a class="reference internal" href="#tensorflow-single-and-multi-node-benchmarks" id="id5">TensorFlow single and multi-node benchmarks</a></li>
<li><a class="reference internal" href="#pytorch-single-and-multi-node-benchmarks" id="id6">PyTorch single and multi-node benchmarks</a></li>
<li><a class="reference internal" href="#kubeflow-multi-node-benchmarks" id="id7">Kubeflow multi-node benchmarks</a></li>
<li><a class="reference internal" href="#tensorflow-training-tfjob-with-kubeflow-and-dlrs" id="id8">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li><a class="reference internal" href="#pytorch-training-pytorch-job-with-kubeflow-and-dlrs" id="id9">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li><a class="reference internal" href="#using-kubeflow-seldon-and-openvino-with-the-deep-learning-reference-stack" id="id10">Using Kubeflow Seldon and OpenVINO* with the Deep Learning Reference Stack</a></li>
<li><a class="reference internal" href="#using-the-intel-openvino-model-optimizer" id="id11">Using the Intel® OpenVINO Model Optimizer</a></li>
<li><a class="reference internal" href="#using-the-openvino-inference-engine" id="id12">Using the OpenVino Inference Engine</a></li>
<li><a class="reference internal" href="#use-jupyter-notebook" id="id13">Use Jupyter Notebook</a></li>
<li><a class="reference internal" href="#uninstallation" id="id14">Uninstallation</a></li>
<li><a class="reference internal" href="#compiling-aixprt-with-openmp-on-dlrs" id="id15">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li><a class="reference internal" href="#related-topics" id="id16">Related topics</a></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id4">Overview</a><a class="headerlink" href="#overview" title="永久链接至标题">¶</a></h2>
<p>We created the Deep Learning Reference Stack to help AI developers deliver
the best experience on Intel® Architecture. This stack reduces complexity
common with deep learning software components, provides flexibility for
customized solutions, and enables you to quickly prototype and deploy Deep
Learning workloads. Use this guide to run benchmarking workloads on your
solution.</p>
<p>The Deep Learning Reference Stack is available in the following versions:</p>
<ul class="simple">
<li><a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dlrs-mkl-vnni">Intel MKL-DNN-VNNI</a>, which is optimized using Intel® Math Kernel Library
for Deep Neural Networks (Intel® MKL-DNN) primitives and introduces support
for Intel® AVX-512 Vector Neural Network Instructions (VNNI).</li>
<li><a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dlrs-mkl/">Intel MKL-DNN</a>, which includes the TensorFlow framework optimized using
Intel® Math Kernel Library for Deep Neural Networks (Intel® MKL-DNN)
primitives.</li>
<li><a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dlrs-oss/">Eigen</a>, which includes <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> optimized for Intel® architecture.</li>
<li><a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-pytorch-oss">PyTorch with OpenBLAS</a>, which includes PyTorch with OpenBlas.</li>
<li><a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-pytorch-mkl">PyTorch with Intel MKL-DNN</a>, which includes PyTorch optimized using Intel®
Math Kernel Library (Intel® MKL) and Intel MKL-DNN.</li>
</ul>
<div class="admonition important">
<p class="first admonition-title">重要</p>
<p>To take advantage of the Intel® AVX-512 and VNNI functionality (including the MKL-DNN releases)  with the Deep
Learning Reference Stack, you must use the following hardware:</p>
<ul class="last simple">
<li>Intel® AVX-512 images require an Intel® Xeon® Scalable Platform</li>
<li>VNNI requires a 2nd generation Intel® Xeon® Scalable Platform</li>
</ul>
</div>
<div class="section" id="stack-features">
<h3>Stack features<a class="headerlink" href="#stack-features" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://clearlinux.org/news-blogs/deep-learning-reference-stack-v4">DLRS V4.0</a> release announcement, including benchmark results.</li>
<li><a class="reference external" href="https://clearlinux.org/stacks/deep-learning-reference-stack-v3">DLRS V3.0</a> release announcement.</li>
<li>Deep Learning Reference Stack v2.0 including current
<a class="reference external" href="https://clearlinux.org/stacks/deep-learning-reference-stack-pytorch">PyTorch benchmark</a>.</li>
<li>Deep Learning Reference Stack v1.0 including current
<a class="reference external" href="https://clearlinux.org/stacks/deep-learning-reference-stack">TensorFlow benchmark</a> results.</li>
<li><a class="reference external" href="https://github.com/clearlinux/dockerfiles/blob/master/stacks/dlrs/releasenote.md">DLRS Release notes</a>  on Github* for the latest release of Deep Learning
Reference Stack.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">The Deep Learning Reference Stack is a collective work, and each piece of
software within the work has its own license.  Please see the <a class="reference external" href="https://clearlinux.org/stacks/deep-learning/terms-of-use">DLRS Terms of Use</a>
for more details about licensing and usage of the Deep Learning Reference Stack.</p>
</div>
</div>
<div class="section" id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li><a class="reference internal" href="../get-started/bare-metal-install-desktop.html#bare-metal-install-desktop"><span class="std std-ref">Install</span></a> Clear Linux OS on your host system</li>
<li><strong class="command">containers-basic</strong> bundle</li>
<li><strong class="command">cloud-native-basic</strong> bundle</li>
</ul>
<p>In Clear Linux OS, <strong class="command">containers-basic</strong> includes Docker*, which is required for
TensorFlow and PyTorch benchmarking. Use the <strong class="command">swupd</strong> utility to
check if <strong class="command">containers-basic</strong> and <strong class="command">cloud-native-basic</strong> are
present:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo swupd bundle-list
</pre></div>
</div>
<p>To install the <strong class="command">containers-basic</strong> or <strong class="command">cloud-native-basic</strong>
bundles, enter:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo swupd bundle-add containers-basic cloud-native-basic
</pre></div>
</div>
<p>Docker is not started upon installation of the <strong class="command">containers-basic</strong>
bundle. To start Docker, enter:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo systemctl start docker
</pre></div>
</div>
<p>To ensure that Kubernetes is correctly installed and configured, follow the
instructions in <a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a>.</p>
</div>
<div class="section" id="version-compatibility">
<h3>Version compatibility<a class="headerlink" href="#version-compatibility" title="永久链接至标题">¶</a></h3>
<p>We validated these steps against the following software package versions:</p>
<ul class="simple">
<li>Clear Linux OS 26240 (Minimum supported version)</li>
<li>Docker 18.06.1</li>
<li>Kubernetes 1.11.3</li>
<li>Go 1.11.12</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">The Deep Learning Reference Stack was developed to provide the best user
experience when executed on a Clear Linux OS host.  However, as the stack runs in a
container environment, you should be able to complete the following sections of this guide on other Linux* distributions, provided they comply with the Docker*, Kubernetes* and Go* package versions listed above. Look for your distribution documentation on how to update packages and manage Docker services.</p>
</div>
</div>
</div>
<div class="section" id="tensorflow-single-and-multi-node-benchmarks">
<h2><a class="toc-backref" href="#id5">TensorFlow single and multi-node benchmarks</a><a class="headerlink" href="#tensorflow-single-and-multi-node-benchmarks" title="永久链接至标题">¶</a></h2>
<p>This section describes running the <a class="reference external" href="https://www.tensorflow.org/guide/performance/benchmarks">TensorFlow Benchmarks</a> in single node.
For multi-node testing, replicate these steps for each node. These steps
provide a template to run other benchmarks, provided that they can invoke
TensorFlow.</p>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Performance test results for the Deep Learning Reference Stack and for this
guide were obtained using <cite>runc</cite> as the runtime.</p>
</div>
<ol class="arabic">
<li><p class="first">Download either the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dlrs-oss/">Eigen</a> or the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dlrs-mkl/">Intel MKL-DNN</a> Docker image
from <a class="reference external" href="https://hub.docker.com/">Docker Hub</a>.</p>
</li>
<li><p class="first">Run the image with Docker:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --name &lt;image name&gt;  --rm -i -t &lt;clearlinux/
stacks-dlrs-TYPE&gt; bash
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Launching the Docker image with the <strong class="command">-i</strong> argument starts
interactive mode within the container. Enter the following commands in
the running container.</p>
</div>
</li>
<li><p class="first">Clone the benchmark repository in the container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone http://github.com/tensorflow/benchmarks -b cnn_tf_v1.12_compatible
</pre></div>
</div>
</li>
<li><p class="first">Execute the benchmark script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --device<span class="o">=</span>cpu --model<span class="o">=</span>resnet50 --data_format<span class="o">=</span>NHWC
</pre></div>
</div>
</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p>You can replace the model with one of your choice supported by the
TensorFlow benchmarks.</p>
<p class="last">If you are using an FP32 based model, it can be converted to an int8 model
using <a class="reference external" href="https://github.com/IntelAI/tools/blob/master/tensorflow_quantization/README.md#quantization-tools">Intel® quantization tools</a>.</p>
</div>
</div>
<div class="section" id="pytorch-single-and-multi-node-benchmarks">
<h2><a class="toc-backref" href="#id6">PyTorch single and multi-node benchmarks</a><a class="headerlink" href="#pytorch-single-and-multi-node-benchmarks" title="永久链接至标题">¶</a></h2>
<p>This section describes running the <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/caffe2/python/convnet_benchmarks.py">PyTorch benchmarks</a> for Caffe2 in
single node.</p>
<ol class="arabic">
<li><p class="first">Download either the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-pytorch-oss">PyTorch with OpenBLAS</a> or the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-pytorch-mkl">PyTorch with Intel
MKL-DNN</a> Docker image from <a class="reference external" href="https://hub.docker.com/">Docker Hub</a>.</p>
</li>
<li><p class="first">Run the image with Docker:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --name &lt;image name&gt;  --rm -i -t &lt;clearlinux/stacks-dlrs-TYPE&gt; bash
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Launching the Docker image with the <strong class="command">-i</strong> argument starts
interactive mode within the container. Enter the following commands in
the running container.</p>
</div>
</li>
<li><p class="first">Clone the benchmark repository:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/pytorch/pytorch.git
</pre></div>
</div>
</li>
<li><p class="first">Execute the benchmark script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> pytorch/caffe2/python
python convnet_benchmarks.py --batch_size <span class="m">32</span> <span class="se">\</span>
                      --cpu <span class="se">\</span>
                      --model AlexNet
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="kubeflow-multi-node-benchmarks">
<h2><a class="toc-backref" href="#id7">Kubeflow multi-node benchmarks</a><a class="headerlink" href="#kubeflow-multi-node-benchmarks" title="永久链接至标题">¶</a></h2>
<p>The benchmark workload runs in a Kubernetes cluster. The guide uses
<a class="reference external" href="https://www.kubeflow.org/">Kubeflow</a> for the Machine Learning workload deployment on three nodes.</p>
<div class="admonition warning">
<p class="first admonition-title">警告</p>
<p class="last">If you choose the Intel® MKL-DNN or Intel® MKL-DNN-VNNI image, your platform
must support the Intel® AVX-512 instruction set. Otherwise, an
<em>illegal instruction</em> error may appear, and you won’t be able to complete this guide.</p>
</div>
<div class="section" id="kubernetes-setup">
<h3>Kubernetes setup<a class="headerlink" href="#kubernetes-setup" title="永久链接至标题">¶</a></h3>
<p>Follow the instructions in the <a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a> tutorial to get set up on
Clear Linux OS. The Kubernetes community also has instructions for creating a cluster,
described in <a class="reference external" href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">Creating a single control-plane cluster with kubeadm</a>.</p>
</div>
<div class="section" id="kubernetes-networking">
<h3>Kubernetes networking<a class="headerlink" href="#kubernetes-networking" title="永久链接至标题">¶</a></h3>
<p>We used <a class="reference external" href="https://github.com/coreos/flannel">flannel</a> as the network provider for these tests. If you
prefer a different network layer, refer to the Kubernetes network documentation
described in <a class="reference external" href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">Creating a single control-plane cluster with kubeadm</a> for setup.</p>
</div>
<div class="section" id="kubectl">
<h3>Kubectl<a class="headerlink" href="#kubectl" title="永久链接至标题">¶</a></h3>
<p>You can use kubectl to run commands against your Kubernetes cluster.  Refer to
the <a class="reference external" href="https://kubernetes.io/docs/reference/kubectl/overview/">Overview of kubectl</a> for details on syntax and operations. Once you have a
working cluster on Kubernetes, use the following YAML script to start a pod with
a simple shell script, and keep the pod open.</p>
<ol class="arabic">
<li><p class="first">Copy this example.yaml script to your system:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: example-pod</span>
<span class="go">  labels:</span>
<span class="go">    app: ex-pod</span>
<span class="go">spec:</span>
<span class="go">  containers:</span>
<span class="go">  - name: ex-pod-container</span>
<span class="go">    image: clearlinux/stacks-dlrs-mkl:latest</span>
<span class="go">    command: [&#39;/bin/bash&#39;, &#39;-c&#39;, &#39;--&#39;]</span>
<span class="go">    args: [ &quot;while true; do sleep 30; done&quot; ]</span>
</pre></div>
</div>
</li>
<li><p class="first">Execute the script with kubectl:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply –f &lt;path-to-yaml-file&gt;/example.yaml
</pre></div>
</div>
</li>
</ol>
<p>This script opens a single pod. More robust solutions would create a deployment
or inject a python script or larger shell script into the container.</p>
</div>
<div class="section" id="images">
<h3>Images<a class="headerlink" href="#images" title="永久链接至标题">¶</a></h3>
<p>You must add <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dlrs/kubeflow">launcher.py</a> to the Docker image to include the Deep
Learning Reference Stack and put the benchmarks repo in the correct
location. Note that this guide uses Kubeflow v0.4.0, and cannot guarantee results if you use a different version.</p>
<p>From the Docker image, run the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir -p /opt
git clone https://github.com/tensorflow/benchmarks.git /opt/tf-benchmarks
cp launcher.py /opt
chmod u+x /opt/*
</pre></div>
</div>
<p>Your entry point becomes: <code class="file docutils literal notranslate"><span class="pre">/opt/launcher.py</span></code>.</p>
<p>This builds an image that can be consumed directly by TFJob from Kubeflow.</p>
</div>
<div class="section" id="ksonnet">
<h3>ksonnet*<a class="headerlink" href="#ksonnet" title="永久链接至标题">¶</a></h3>
<p>Kubeflow uses ksonnet* to manage deployments, so you must install it
before setting up Kubeflow.</p>
<p>ksonnet was added to the <strong class="command">cloud-native-basic</strong> bundle in Clear Linux OS version
27550. If you are using an older Clear Linux OS version (not recommended), you must
manually install ksonnet as described below.</p>
<p>On Clear Linux OS, follow these steps:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>swupd bundle-add go-basic-dev
<span class="nb">export</span> <span class="nv">GOPATH</span><span class="o">=</span><span class="nv">$HOME</span>/go
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$GOPATH</span>/bin
go get github.com/ksonnet/ksonnet
<span class="nb">cd</span> <span class="nv">$GOPATH</span>/src/github.com/ksonnet/ksonnet
make install
</pre></div>
</div>
<p>After the ksonnet installation is complete, ensure that binary <cite>ks</cite> is
accessible across the environment.</p>
</div>
<div class="section" id="kubeflow">
<h3>Kubeflow<a class="headerlink" href="#kubeflow" title="永久链接至标题">¶</a></h3>
<p>Once you have Kubernetes running on your nodes, set up <a class="reference external" href="https://www.kubeflow.org/">Kubeflow</a> by
following these instructions from the <a class="reference external" href="https://www.kubeflow.org/docs/started/getting-started/">Getting Started with Kubeflow</a> guide.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">KUBEFLOW_SRC</span><span class="o">=</span><span class="nv">$HOME</span>/kflow
<span class="nb">export</span> <span class="nv">KUBEFLOW_TAG</span><span class="o">=</span><span class="s2">&quot;v0.4.1&quot;</span>
<span class="nb">export</span> <span class="nv">KFAPP</span><span class="o">=</span><span class="s2">&quot;kflow_app&quot;</span>
<span class="nb">export</span> <span class="nv">K8S_NAMESPACE</span><span class="o">=</span><span class="s2">&quot;kubeflow&quot;</span>

mkdir <span class="si">${</span><span class="nv">KUBEFLOW_SRC</span><span class="si">}</span>
<span class="nb">cd</span> <span class="si">${</span><span class="nv">KUBEFLOW_SRC</span><span class="si">}</span>
ks init <span class="si">${</span><span class="nv">KFAPP</span><span class="si">}</span>
<span class="nb">cd</span> <span class="si">${</span><span class="nv">KFAPP</span><span class="si">}</span>
ks registry add kubeflow github.com/kubeflow/kubeflow/tree/<span class="si">${</span><span class="nv">KUBEFLOW_TAG</span><span class="si">}</span>/kubeflow
ks pkg install kubeflow/common
ks pkg install kubeflow/tf-training
</pre></div>
</div>
<p>Next, deploy the primary package for our purposes: tf-job-operator.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ks env rm default
kubectl create namespace <span class="si">${</span><span class="nv">K8S_NAMESPACE</span><span class="si">}</span>
ks env add default --namespace <span class="s2">&quot;</span><span class="si">${</span><span class="nv">K8S_NAMESPACE</span><span class="si">}</span><span class="s2">&quot;</span>
ks generate tf-job-operator tf-job-operator
ks apply default -c tf-job-operator
</pre></div>
</div>
<p>This creates the CustomResourceDefinition (CRD) endpoint to launch a TFJob.</p>
</div>
<div class="section" id="run-a-tfjob">
<h3>Run a TFJob<a class="headerlink" href="#run-a-tfjob" title="永久链接至标题">¶</a></h3>
<ol class="arabic">
<li><p class="first">Get the ksonnet registries for deploying TFJobs from <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dlrs/kubeflow/dlrs-tfjob">dlrs-tfjob</a>.</p>
</li>
<li><p class="first">Install the TFJob components as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ks registry add dlrs-tfjob github.com/clearlinux/dockerfiles/tree/master/stacks/dlrs/kubeflow/dlrs-tfjob

ks pkg install dlrs-tfjob/dlrs-bench
</pre></div>
</div>
</li>
<li><p class="first">Export the image name to use for the deployment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">DLRS_IMAGE</span><span class="o">=</span>&lt;docker_name&gt;
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Replace &lt;docker_name&gt; with the image name you specified in previous steps.</p>
</div>
</li>
<li><p class="first">Generate Kubernetes manifests for the workloads and apply them using these
commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ks generate dlrs-resnet50 dlrsresnet50 --name<span class="o">=</span>dlrsresnet50 --image<span class="o">=</span><span class="si">${</span><span class="nv">DLRS_IMAGE</span><span class="si">}</span>
ks generate dlrs-alexnet dlrsalexnet --name<span class="o">=</span>dlrsalexnet --image<span class="o">=</span><span class="si">${</span><span class="nv">DLRS_IMAGE</span><span class="si">}</span>
ks apply default -c dlrsresnet50
ks apply default -c dlrsalexnet
</pre></div>
</div>
</li>
</ol>
<p>This replicates and deploys three test setups in your Kubernetes cluster.</p>
</div>
<div class="section" id="results-of-running-this-section">
<h3>Results of running this section<a class="headerlink" href="#results-of-running-this-section" title="永久链接至标题">¶</a></h3>
<p>You must parse the logs of the Kubernetes pod to retrieve performance
data. The pods will still exist post-completion and will be in
‘Completed’ state. You can get the logs from any of the pods to inspect the
benchmark results. More information about Kubernetes logging is available
in the Kubernetes <a class="reference external" href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Logging Architecture</a> documentation.</p>
</div>
</div>
<div class="section" id="tensorflow-training-tfjob-with-kubeflow-and-dlrs">
<h2><a class="toc-backref" href="#id8">TensorFlow Training (TFJob) with Kubeflow and DLRS</a><a class="headerlink" href="#tensorflow-training-tfjob-with-kubeflow-and-dlrs" title="永久链接至标题">¶</a></h2>
<p>A <a class="reference external" href="https://www.kubeflow.org/docs/components/tftraining">TFJob</a>  is Kubeflow’s custom resource used to run TensorFlow training jobs on Kubernetes. This example shows how to use a TFJob within the DLRS container.</p>
<p>Pre-requisites:</p>
<ul class="simple">
<li>A running <a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a> cluster</li>
</ul>
<ol class="arabic simple">
<li>Deploying Kubeflow with kfctl/kustomize in Clear Linux OS</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">This example proposes a Kubeflow installation with the binary kfctl maintained by <a class="reference external" href="https://www.kubeflow.org/docs/started/k8s/kfctl-existing-arrikto/">Arrikto</a>. Please download the <a class="reference external" href="https://github.com/kubeflow/kubeflow/releases/download/v0.6.1/kfctl_v0.6.1_linux.tar.gz">kfctl tarball</a> to complete the following steps</p>
</div>
<ol class="arabic">
<li><p class="first">Download, untar and add to your PATH if necessary</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">KFCTL_URL</span><span class="o">=</span><span class="s2">&quot;https://github.com/kubeflow/kubeflow/releases/download/v0.6.1/kfctl_v0.6.1_linux.tar.gz&quot;</span>
wget -P <span class="si">${</span><span class="nv">KFCTL_URL</span><span class="si">}</span> <span class="si">${</span><span class="nv">KFCTL_PATH</span><span class="si">}</span>
tar -C <span class="si">${</span><span class="nv">KFCTL_PATH</span><span class="si">}</span> -xvf <span class="si">${</span><span class="nv">KFCTL_PATH</span><span class="si">}</span>/kfctl_v<span class="si">${</span><span class="nv">kfctl_ver</span><span class="si">}</span>_linux.tar.gz
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="si">${</span><span class="nv">KFCTL_PATH</span><span class="si">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Install <a class="reference external" href="https://metallb.universe.tf/">MetalLB</a></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml
</pre></div>
</div>
</li>
<li><p class="first">Install Kubeflow resource and TFJob operators</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Env variables needed for your deployment</span>
<span class="nb">export</span> <span class="nv">KFAPP</span><span class="o">=</span><span class="s2">&quot;&lt;your choice of application directory name&gt;&quot;</span>
<span class="nb">export</span> <span class="nv">CONFIG</span><span class="o">=</span><span class="s2">&quot;https://raw.githubusercontent.com/kubeflow/kubeflow/master/bootstrap/config/kfctl_existing_arrikto.yaml&quot;</span>

kfctl init <span class="si">${</span><span class="nv">KFAPP</span><span class="si">}</span> --config<span class="o">=</span><span class="si">${</span><span class="nv">CONFIG</span><span class="si">}</span> -V
<span class="nb">cd</span> <span class="si">${</span><span class="nv">KFAPP</span><span class="si">}</span>

<span class="c1"># deploy Kubeflow:</span>
kfctl generate k8s -V
kfctl apply k8s -V
</pre></div>
</div>
</li>
<li><p class="first">List the resources</p>
<p>Deployment takes around 15 minutes (or more depending on the hardware) to be ready to use. After that you can use kubectl to list all the Kubeflow resources deployed and monitor their status.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -n kubeflow
</pre></div>
</div>
</li>
</ol>
<div class="section" id="submitting-tfjobs">
<h3>Submitting TFJobs<a class="headerlink" href="#submitting-tfjobs" title="永久链接至标题">¶</a></h3>
<p>We provide several <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dlrs/kubeflow/dlrs-tfjob">DLRS TFJob</a> examples that use the Deep Learning Reference Stack as the base image for creating the containers to run training workloads in your Kubernetes cluster.</p>
</div>
<div class="section" id="customizing-a-tfjob">
<h3>Customizing a TFJob<a class="headerlink" href="#customizing-a-tfjob" title="永久链接至标题">¶</a></h3>
<p>A TFJob is a resource with a YAML representation like the one below. Edit to use the DLRS image containing the code to be executed and modify the command for your own training code.</p>
<p>If you’d like to modify the number and type of replicas, resources, persistent volumes and environment variables, please refer to the <a class="reference external" href="https://www.kubeflow.org/docs/components/tftraining/#what-is-tfjob">Kubeflow documentation</a></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">apiVersion: kubeflow.org/v1beta2</span>
<span class="go">kind: TFJob</span>
<span class="go">metadata:</span>
<span class="go">  generateName: tfjob</span>
<span class="go">  namespace: kubeflow</span>
<span class="go">spec:</span>
<span class="go">  tfReplicaSpecs:</span>
<span class="go">    PS:</span>
<span class="go">      replicas: 1</span>
<span class="go">      restartPolicy: OnFailure</span>
<span class="go">      template:</span>
<span class="go">        spec:</span>
<span class="go">          containers:</span>
<span class="go">          - name: tensorflow</span>
<span class="go">            image: dlrs-image</span>
<span class="go">            command:</span>
<span class="go">              - python</span>
<span class="go">              - -m</span>
<span class="go">              - trainer.task</span>
<span class="go">              - --batch_size=32</span>
<span class="go">              - --training_steps=1000</span>
<span class="go">    Worker:</span>
<span class="go">      replicas: 3</span>
<span class="go">      restartPolicy: OnFailure</span>
<span class="go">      template:</span>
<span class="go">        spec:</span>
<span class="go">          containers:</span>
<span class="go">          - name: tensorflow</span>
<span class="go">            image: dlrs-image</span>
<span class="go">            command:</span>
<span class="go">              - python</span>
<span class="go">              - -m</span>
<span class="go">              - trainer.task</span>
<span class="go">              - --batch_size=32</span>
<span class="go">              - --training_steps=1000</span>
<span class="go">    Master:</span>
<span class="go">          replicas: 1</span>
<span class="go">          restartPolicy: OnFailure</span>
<span class="go">          template:</span>
<span class="go">            spec:</span>
<span class="go">              containers:</span>
<span class="go">              - name: tensorflow</span>
<span class="go">                image: dlrs-image</span>
<span class="go">                command:</span>
<span class="go">                  - python</span>
<span class="go">                  - -m</span>
<span class="go">                  - trainer.task</span>
<span class="go">                  - --batch_size=32</span>
<span class="go">                  - --training_steps=1000</span>
</pre></div>
</div>
<p>For more information, please refer to:
* <a class="reference external" href="https://www.tensorflow.org/deploy/distributed">Distributed TensorFlow</a>
* <a class="reference external" href="https://www.kubeflow.org/docs/components/tftraining/">TFJobs</a></p>
</div>
</div>
<div class="section" id="pytorch-training-pytorch-job-with-kubeflow-and-dlrs">
<h2><a class="toc-backref" href="#id9">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a><a class="headerlink" href="#pytorch-training-pytorch-job-with-kubeflow-and-dlrs" title="永久链接至标题">¶</a></h2>
<p>A <a class="reference external" href="https://www.kubeflow.org/docs/components/pytorch/">PyTorch Job</a> is Kubeflow’s custom resource used to run PyTorch training jobs on Kubernetes. This example builds on the framework set up in the previous example.</p>
<p>Pre-requisites:</p>
<ul class="simple">
<li>A running <a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a> cluster</li>
<li>Please follow steps 1 - 5 of the previous example to set up your environment.</li>
</ul>
<div class="section" id="submitting-pytorch-jobs">
<h3>Submitting PyTorch Jobs<a class="headerlink" href="#submitting-pytorch-jobs" title="永久链接至标题">¶</a></h3>
<p>We provide several <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dlrs/kubeflow/dlrs-pytorchjob">DLRS PytorchJob</a> examples that use the Deep Learning Reference Stack as the base image for creating the container(s) that will run training workloads in your Kubernetes cluster.
Select one form the list below:</p>
</div>
</div>
<div class="section" id="using-kubeflow-seldon-and-openvino-with-the-deep-learning-reference-stack">
<h2><a class="toc-backref" href="#id10">Using Kubeflow Seldon and OpenVINO* with the Deep Learning Reference Stack</a><a class="headerlink" href="#using-kubeflow-seldon-and-openvino-with-the-deep-learning-reference-stack" title="永久链接至标题">¶</a></h2>
<p><a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/">Seldon Core</a>  is an open source platform for deploying machine learning models on a Kubernetes cluster.  Seldon Core is supported in the <a class="reference external" href="https://clearlinux.org/news-blogs/deep-learning-reference-stack-v4">DLRS V4.0</a> release.</p>
<div class="section" id="pre-requisites">
<h3>Pre-requisites<a class="headerlink" href="#pre-requisites" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>A running <a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a> cluster</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Instead of using Arrikto’s configuration manifest as shown  in the preceeding example, you should use the manifest provided by <a class="reference external" href="https://raw.githubusercontent.com/kubeflow/kubeflow/master/bootstrap/config/kfctl_k8s_istio.yaml">Istio</a>, for this example, as Seldon deployments depend on it.</p>
</div>
<ol class="arabic">
<li><p class="first">Install deployment tools</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">INSTALL_DIR</span><span class="o">=</span><span class="nv">$HOME</span>/install_dir
<span class="nv">BIN_DIR</span><span class="o">=</span><span class="si">${</span><span class="nv">INSTALL_DIR</span><span class="si">}</span>/bin
<span class="nv">SRC_DIR</span><span class="o">=</span><span class="si">${</span><span class="nv">INSTALL_DIR</span><span class="si">}</span>/source
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">BIN_DIR</span><span class="si">}</span>:<span class="nv">$PATH</span>

mkdir -p <span class="si">${</span><span class="nv">BIN_DIR</span><span class="si">}</span> <span class="o">&amp;&amp;</span> mkdir <span class="si">${</span><span class="nv">SRC_DIR</span><span class="si">}</span>
<span class="nb">cd</span> <span class="si">${</span><span class="nv">SRC_DIR</span><span class="si">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Install Helm*</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz <span class="o">&amp;&amp;</span> tar xf helm-v2.14.3-linux-amd64.tar.gz
mv linux-amd64/helm <span class="si">${</span><span class="nv">BIN_DIR</span><span class="si">}</span>/helm
</pre></div>
</div>
</li>
<li><p class="first">Clean the environment</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rm -rf <span class="si">${</span><span class="nv">SRC_DIR</span><span class="si">}</span>/*
</pre></div>
</div>
</li>
<li><p class="first">Prepare the DLRS image</p>
<p>The DLRS base image needs to be rebuilt with the <a class="reference external" href="https://github.com/clearlinux/dockerfiles/blob/master/stacks/dlrs/kubeflow/dlrs-seldon/docker/Dockerfile_openvino_base">Dockerfile_openvino_base</a>  to add Seldon and the OpenVINO inference engine.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker build -f Dockerfile_openvino_base -t dlrs_openvino_base:0.1 .
</pre></div>
</div>
</li>
<li><p class="first">Mount pre-trained models into a persistent volume</p>
<p>This will also apply all PV manifests to the cluster</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl apply -f storage/pv-volume.yaml
kubectl apply -f storage/model-store-pvc.yaml
kubectl apply -f storage/pv-pod.yaml
</pre></div>
</div>
</li>
<li><p class="first">Start a shell for the container used as pv:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it hostpath-pvc -- /bin/bash
</pre></div>
</div>
</li>
<li><p class="first">Save pre-trained models</p>
<p>Now that you’re inside the running container, fetch your pre-trained models and save them at <cite>/opt/ml</cite></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@hostpath-pvc:/# <span class="nb">cd</span> /opt/ml
root@hostpath-pvc:/# <span class="c1"># Copy your models here</span>
root@hostpath-pvc:/# <span class="c1"># exit</span>
</pre></div>
</div>
</li>
<li><p class="first">Deploy the model server</p>
<p>Now you’re ready to deploy the model server using the Helm chart provided.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install -- <span class="nv">name</span><span class="o">=</span>seldonov-model-server <span class="se">\</span>
   --namespace kubeflow <span class="se">\</span>
   --set openvino.image<span class="o">=</span>dlrs_openvino_base:0.1 <span class="se">\</span>
   --set openvino.model.path<span class="o">=</span>/opt/ml/&lt;models_directory&gt; <span class="se">\</span>
   --set openvino.model.name<span class="o">=</span>&lt;model_name&gt; <span class="se">\</span>
   --set openvino.model.input<span class="o">=</span>data <span class="se">\</span>
   --set openvino.model.output<span class="o">=</span>prob
   dlrs-seldon/helm/seldon-model-server
</pre></div>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="using-the-intel-openvino-model-optimizer">
<h2><a class="toc-backref" href="#id11">Using the Intel® OpenVINO Model Optimizer</a><a class="headerlink" href="#using-the-intel-openvino-model-optimizer" title="永久链接至标题">¶</a></h2>
<p>The Intel OpenVINO toolkit has two primary tools for deep learning, the inference engine and the model optimizer. The inference engine is integrated into the Deep Learning Reference Stack. It is better to use the model optimizer after training the model, and before inference begins. This example will explain how to use the model optimizer by going through a test case with a pre-trained TensorFlow model.</p>
<p>This example uses resources found in the following OpenVino Toolkit documentation.</p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">Converting a TensorFlow Model</a></p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">Converting TensorFlow Object Detection API Models</a></p>
<p>In this example, you will:</p>
<ul class="simple">
<li>Download a TensorFlow model</li>
<li>Clone the Model Optimizer</li>
<li>Install Prerequisites</li>
<li>Run the Model Optimizer</li>
</ul>
<ol class="arabic">
<li><p class="first">Download a TensorFlow model</p>
<p>We will be using an OpenVINO supported topology with the Model Optimizer. We will use a TensorFlow Inception V2 frozen model.</p>
<p>Navigate to the <a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">OpenVINO TensorFlow Model page</a>. Then scroll down to the second section titled “Supported Frozen Topologies from TensorFlow Object Detection Models Zoo” and download “SSD Inception V2 COCO.”</p>
<p>Unpack the file into your chosen working directory. For example, if the tar file is in your Downloads folder and you have navigated to the directory you want to extract it into, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar -xvf ~/Downloads/ssd_inception_v2_coco_2018_01_28.tar.gz
</pre></div>
</div>
</li>
<li><p class="first">Clone the Model Optimizer</p>
<p>Next we need the model optimizer directory, named <a class="reference external" href="https://github.com/opencv/dldt">dldt</a>.  This example  assumes the parent directory is on the same level as the model directory, ie:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+--Working_Directory</span>
<span class="go">   +-- ssd_inception_v2_coco_2018_01_28</span>
<span class="go">   +-- dldt</span>
</pre></div>
</div>
<p>To clone the Model Optimizer, run this from inside the working directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/opencv/dldt.git
</pre></div>
</div>
<p>If you explore the <code class="file docutils literal notranslate"><span class="pre">dldt</span></code> directory, you’ll see both the inference engine and the model optimizer. We are only concerned with the model optimizer at this stage. Navigating into the model optimizer folder you’ll find several python scripts and text files. These are the scripts you call to run the model optimizer.</p>
</li>
<li><p class="first">Install Prerequisites for Model Optimizer</p>
<p>Install the Python packages required to run the model optimizer by running the script dldt/model-optimizer/install_prerequisites/install_prerequisites_tf.sh.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> dldt/model-optimizer/install_prerequisites/
./install_prerequisites_tf.sh
<span class="nb">cd</span> ../../..
</pre></div>
</div>
</li>
<li><p class="first">Run the Model Optimizer</p>
<p>Running the model optimizer is as simple as calling the appropriate script, however there are many configuration options that are explainedin the documentation</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python dldt/model-optimizer/mo_tf.py <span class="se">\</span>
--input_model<span class="o">=</span>ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb <span class="se">\</span>
--tensorflow_use_custom_operations_config dldt/model-optimizer/extensions/front/tf/ssd_v2_support.json <span class="se">\</span>
--tensorflow_object_detection_api_pipeline_config ssd_inception_v2_coco_2018_01_28/pipeline.config <span class="se">\</span>
--reverse_input_channels
</pre></div>
</div>
<p>You should now see three files in your working directory, <code class="file docutils literal notranslate"><span class="pre">frozen_inference_graph.bin</span></code>, <code class="file docutils literal notranslate"><span class="pre">frozen_inference_graph.mapping</span></code>, and <code class="file docutils literal notranslate"><span class="pre">frozen_inference_graph.xml</span></code>. These are your new models in the Intermediate Representation (IR) format and they are ready for use in the OpenVINO Inference Engine.</p>
</li>
</ol>
</div>
<div class="section" id="using-the-openvino-inference-engine">
<h2><a class="toc-backref" href="#id12">Using the OpenVino Inference Engine</a><a class="headerlink" href="#using-the-openvino-inference-engine" title="永久链接至标题">¶</a></h2>
<p>This example walks through the basic instructions for using the inference engine.</p>
<ol class="arabic">
<li><p class="first">Starting the Model Server</p>
<p>The process is similar to how we start <cite>Jupter notebooks</cite> on our containers</p>
<p>Run this command to spin up a OpenVino model fetched from GCP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run -p <span class="m">8000</span>:8000 stacks-tensorflow-mkl:latest bash -c <span class="s2">&quot;. /workspace/scripts/serve.sh &amp;&amp; ie_serving model --model_name resnet --model_path gs://intelai_public_models/resnet_50_i8 --port 8000&quot;</span>
</pre></div>
</div>
<p>Once the server is setup, use a <strong class="command">grpc</strong> client to communicate with served model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/IntelAI/OpenVINO-model-server.git
<span class="nb">cd</span> OpenVINO-model-server
pip install -q -r OpenVINO-model-server/example_client/client_requirements.txt
pip install --user -q -r OpenVINO-model-server/example_client/client_requirements.txt
cat OpenVINO-model-server/example_client/client_requirements.txt
<span class="nb">cd</span> OpenVINO-model-server/example_client

python jpeg_classification.py --images_list input_images.txt --grpc_address localhost --grpc_port <span class="m">8000</span> --input_name data --output_name prob --size <span class="m">224</span> --model_name resnet
</pre></div>
</div>
<p>The results of these commands will look like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">start processing:</span>
<span class="go">       Model name: resnet</span>
<span class="go">       Images list file: input_images.txt</span>
<span class="go">images/airliner.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 97.00 ms; speed 2.00 fps 10.35</span>
<span class="go">Detected: 404  Should be: 404</span>
<span class="go">images/arctic-fox.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 16.00 ms; speed 2.00 fps 63.89</span>
<span class="go">Detected: 279  Should be: 279</span>
<span class="go">images/bee.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 14.00 ms; speed 2.00 fps 69.82</span>
<span class="go">Detected: 309  Should be: 309</span>
<span class="go">images/golden_retriever.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 13.00 ms; speed 2.00 fps 75.22</span>
<span class="go">Detected: 207  Should be: 207</span>
<span class="go">images/gorilla.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 11.00 ms; speed 2.00 fps 87.24</span>
<span class="go">Detected: 366  Should be: 366</span>
<span class="go">images/magnetic_compass.jpeg (1, 3, 224, 224) ; data range: 0.0 : 247.0</span>
<span class="go">Processing time: 11.00 ms; speed 2.00 fps 91.07</span>
<span class="go">Detected: 635  Should be: 635</span>
<span class="go">images/peacock.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 9.00 ms; speed 2.00 fps 110.1</span>
<span class="go">Detected: 84  Should be: 84</span>
<span class="go">images/pelican.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 10.00 ms; speed 2.00 fps 103.63</span>
<span class="go">Detected: 144  Should be: 144</span>
<span class="go">images/snail.jpeg (1, 3, 224, 224) ; data range: 0.0 : 248.0</span>
<span class="go">Processing time: 10.00 ms; speed 2.00 fps 104.33</span>
<span class="go">Detected: 113  Should be: 113</span>
<span class="go">images/zebra.jpeg (1, 3, 224, 224) ; data range: 0.0 : 255.0</span>
<span class="go">Processing time: 12.00 ms; speed 2.00 fps 83.04</span>
<span class="go">Detected: 340  Should be: 340</span>
<span class="go">Overall accuracy= 100.0 %</span>
<span class="go">Average latency= 19.8 ms</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="use-jupyter-notebook">
<h2><a class="toc-backref" href="#id13">Use Jupyter Notebook</a><a class="headerlink" href="#use-jupyter-notebook" title="永久链接至标题">¶</a></h2>
<p>This example uses the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-pytorch-oss">PyTorch with OpenBLAS</a> container image. After it is
downloaded, run the Docker image with <strong class="command">-p</strong> to specify the shared port
between the container and the host. This example uses port 8888.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --name pytorchtest --rm -i -t -p <span class="m">8888</span>:8888 clearlinux/stacks-pytorch-oss bash
</pre></div>
</div>
<p>After you start the container, launch the Jupyter Notebook. This
command is executed inside the container image.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>jupyter notebook --ip <span class="m">0</span>.0.0.0 --no-browser --allow-root
</pre></div>
</div>
<p>After the notebook has loaded, you will see output similar to the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">To access the notebook, open this file in a browser: file:///.local/share/jupyter/runtime/nbserver-16-open.html</span>
<span class="go">Or copy and paste one of these URLs:</span>
<span class="go">http://(846e526765e3 or 127.0.0.1):8888/?token=6357dbd072bea7287c5f0b85d31d70df344f5d8843fbfa09</span>
</pre></div>
</div>
<p>From your host system, or any system that can access the host’s IP address,
start a web browser with the following. If you are not running the browser on
the host system, replace <strong class="command">127.0.0.1</strong> with the IP address of the host.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>http://127.0.0.1:8888/?token<span class="o">=</span>6357dbd072bea7287c5f0b85d31d70df344f5d8843fbfa09
</pre></div>
</div>
<p>Your browser displays the following:</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/dlrs-fig-11.png"><img alt="Jupyter Notebook" src="../_images/dlrs-fig-11.png" style="width: 520.0px; height: 201.0px;" /></a>
</div>
<p>Figure 1: <span class="guilabel">Jupyter Notebook</span></p>
<p>To create a new notebook, click <span class="guilabel">New</span> and select <span class="guilabel">Python 3</span>.</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/dlrs-fig-21.png"><img alt="Create a new notebook" src="../_images/dlrs-fig-21.png" style="width: 548.5px; height: 241.5px;" /></a>
</div>
<p>Figure 2: Create a new notebook</p>
<p>A new, blank notebook is displayed, with a cell ready for input.</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/dlrs-fig-31.png"><img alt="New blank notebook" src="../_images/dlrs-fig-31.png" style="width: 550.5px; height: 254.0px;" /></a>
</div>
<p>To verify that PyTorch is working, copy the following snippet into the blank
cell, and run the cell.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">from __future__ import print_function</span>
<span class="go">import torch</span>
<span class="go">x = torch.rand(5, 3)</span>
<span class="go">print(x)</span>
</pre></div>
</div>
<div class="figure">
<a class="reference internal image-reference" href="../_images/dlrs-fig-41.png"><img alt="Sample code snippet" src="../_images/dlrs-fig-41.png" style="width: 550.5px; height: 253.0px;" /></a>
</div>
<p>When you run the cell, your output will look something like this:</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/dlrs-fig-51.png"><img alt="code output" src="../_images/dlrs-fig-51.png" style="width: 550.0px; height: 252.5px;" /></a>
</div>
<p>You can continue working in this notebook, or you can download existing
notebooks to take advantage of the Deep Learning Reference Stack’s optimized
deep learning frameworks. Refer to <a class="reference external" href="https://jupyter.org/">Jupyter Notebook</a> for details.</p>
</div>
<div class="section" id="uninstallation">
<h2><a class="toc-backref" href="#id14">Uninstallation</a><a class="headerlink" href="#uninstallation" title="永久链接至标题">¶</a></h2>
<p>To uninstall the Deep Learning Reference Stack, you can choose to stop the
container so that it is not using system resources, or you can stop the
container and delete it to free storage space.</p>
<p>To stop the container, execute the following from your host system:</p>
<ol class="arabic">
<li><p class="first">Find the container’s ID</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker container ls
</pre></div>
</div>
<p>This will result in output similar to the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">CONTAINER ID        IMAGE                        COMMAND               CREATED             STATUS              PORTS               NAMES</span>
<span class="go">e131dc71d339        clearlinux/stacks-dlrs-oss   &quot;/bin/sh -c &#39;bash&#39;&quot;   23 seconds ago      Up 21 seconds                           oss</span>
</pre></div>
</div>
</li>
<li><p class="first">You can then use the ID or container name to stop the container. This example
uses the name “oss”:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker container stop oss
</pre></div>
</div>
</li>
<li><p class="first">Verify that the container is not running</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker container ls
</pre></div>
</div>
</li>
<li><p class="first">To delete the container from your system you need to know the Image ID:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker images
</pre></div>
</div>
<p>This command results in output similar to the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE</span>
<span class="go">clearlinux/stacks-dlrs-oss   latest              82757ec1648a        4 weeks ago         3.43GB</span>
<span class="go">clearlinux/stacks-dlrs-mkl   latest              61c178102228        4 weeks ago         2.76GB</span>
</pre></div>
</div>
</li>
<li><p class="first">To remove an image use the image ID:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker rmi 82757ec1648a
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> docker rmi <span class="m">827</span>
<span class="go">Untagged: clearlinux/stacks-dlrs-oss:latest</span>
<span class="go">Untagged: clearlinux/stacks-dlrs-oss@sha256:381f4b604537b2cb7fb5b583a8a847a50c4ed776f8e677e2354932eb82f18898</span>
<span class="go">Deleted: sha256:82757ec1648a906c504e50e43df74ad5fc333deee043dbfe6559c86908fac15e</span>
<span class="go">Deleted: sha256:e47ecc039d48409b1c62e5ba874921d7f640243a4c3115bb41b3e1009ecb48e4</span>
<span class="go">Deleted: sha256:50c212235d3c33a3c035e586ff14359d03895c7bc701bb5dfd62dbe0e91fb486</span>
</pre></div>
</div>
<p>Note that you can execute the <strong class="command">docker rmi</strong> command using only the first few characters of the image ID, provided they are unique on the system.</p>
</li>
<li><p class="first">Once you have removed the image, you can verify it has been deleted with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker images
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="compiling-aixprt-with-openmp-on-dlrs">
<h2><a class="toc-backref" href="#id15">Compiling AIXPRT with OpenMP on DLRS</a><a class="headerlink" href="#compiling-aixprt-with-openmp-on-dlrs" title="永久链接至标题">¶</a></h2>
<p>To compile AIXPRT for DLRS, you will have to get the community edition of AIXPRT and update the <cite>compile_AIXPRT_source.sh</cite> file.AIXPRT utilizes
build configuration files, so to build AIXPRT on the image, copy, the build files from the base image, this can be done by adding these commands
to the end of the stacks-tensorflow-mkl dockerfile:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">COPY --from=base /dldt/inference-engine/bin/intel64/Release/ /usr/local/lib/openvino/tools/</span>
<span class="go">COPY --from=base /dldt/ /dldt/</span>
<span class="go">COPY ./airxprt/ /workspace/aixprt/</span>
<span class="go">RUN ./aixprt/install_deps.sh</span>
<span class="go">RUN ./aixprt/install_aixprt.sh</span>
</pre></div>
</div>
</div></blockquote>
<p>AIXPRT requires OpenCV. On Clear Linux OS, the OpenCV bundle also installs the DLDT components. To use AIXPRT in the DLRS environment you need to either remove the shared libraries for DLDT from <code class="file docutils literal notranslate"><span class="pre">/usr/lib64</span></code> before you run the tests, or ensure that the DLDT components in the <code class="file docutils literal notranslate"><span class="pre">/usr/local/lib</span></code> are being used for AIXPRT.  This can be achieved using adding LD_LIBRARY_PATH environment variable before testing.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/lib
</pre></div>
</div>
</div></blockquote>
<p>The updates to the AIXPRT community edition have been captured in the diff file <code class="file docutils literal notranslate"><span class="pre">compile_AIXPRT_source.sh.patch</span></code>. The core of these changes relate to the version of model files(2019_R1) we download from the <a class="reference external" href="https://github.com/opencv/open_model_zoo">OpenCV open model zoo</a> and location of the build files, which in our case is <cite>/dldt</cite>. Please refer to the patch files and make changes as necessary to the compile_AIXPRT_source.sh file as required for your environment.</p>
</div>
<div class="section" id="related-topics">
<h2><a class="toc-backref" href="#id16">Related topics</a><a class="headerlink" href="#related-topics" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://clearlinux.org/stacks/deep-learning-reference-stack-v3">DLRS V3.0</a> release announcement</li>
<li><a class="reference external" href="https://www.tensorflow.org/guide/performance/benchmarks">TensorFlow Benchmarks</a></li>
<li><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/caffe2/python/convnet_benchmarks.py">PyTorch benchmarks</a></li>
<li><a class="reference external" href="https://www.kubeflow.org/">Kubeflow</a></li>
<li><a class="reference internal" href="kubernetes.html#kubernetes"><span class="std std-ref">Kubernetes*</span></a> tutorial</li>
<li><a class="reference external" href="https://jupyter.org/">Jupyter Notebook</a></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="docker.html" class="btn btn-neutral float-right" title="Docker*" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="apache-spark.html" class="btn btn-neutral float-left" title="Apache* Spark*" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019.
      <span class="lastupdated">
        最后更新于 1月 17, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>

<div id="trademarks">
  <p>*Other names and brands may be claimed as the property of others.</p>
</div>


      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  

<script type="text/javascript" src="../_static/tcs_theme.js"></script>



</body>
</html>